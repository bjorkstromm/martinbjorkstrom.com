<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
	<link rel="self" href="http://martinbjorkstrom.com/" />
	<id>http://martinbjorkstrom.com/</id>
	<title>Martin Björkström</title>
	<rights>2020</rights>
	<updated>2020-04-06T19:12:59Z</updated>
	<subtitle>Driving Digital Transformation on Serverless Containers...</subtitle>
	<entry>
		<link href="http://martinbjorkstrom.com/posts/2020-02-12-testing-protected-azure-functions" />
		<id>http://martinbjorkstrom.com/posts/2020-02-12-testing-protected-azure-functions</id>
		<title>Testing protected Azure Functions running in a container on your local machine</title>
		<updated>2020-02-12T00:00:00Z</updated>
		<content>&lt;p&gt;Recently I had to create an Azure Function using a custom container. The reason was a client of mine did some really cool things using Puppeteer, and now they wanted to run this in an Azure Function. So, I went to &lt;a href="https://docs.microsoft.com"&gt;docs.microsoft.com&lt;/a&gt; and found a great &lt;a href="https://docs.microsoft.com/en-us/azure/azure-functions/functions-create-function-linux-custom-image?tabs=portal%2Cbash&amp;amp;pivots=programming-language-csharp"&gt;tutorial&lt;/a&gt; on how to create a function on Linux using a custom container. However, a little bit into the tutorial, in the &lt;a href="https://docs.microsoft.com/en-us/azure/azure-functions/functions-create-function-linux-custom-image?tabs=portal%2Cbash&amp;amp;pivots=programming-language-csharp"&gt;build the container image and test locally&lt;/a&gt; section, I noticed something very annoying, namely this:&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;Once the image is running in a local container, open a browser to &lt;a href="http://localhost:8080,"&gt;http://localhost:8080,&lt;/a&gt; which should display the placeholder image shown below. The image appears at this point because your function is running in the local container, as it would in Azure, which means that it's protected by an access key as defined in function.json with the &amp;quot;authLevel&amp;quot;: &amp;quot;function&amp;quot; property. The container hasn't yet been published to a function app in Azure, however, so the key isn't yet available. &lt;strong&gt;If you want to test locally, stop docker, change the authorization property to &amp;quot;authLevel&amp;quot;: &amp;quot;anonymous&amp;quot;, rebuild the image, and restart docker. Then reset &amp;quot;authLevel&amp;quot;: &amp;quot;function&amp;quot; in function.json.&lt;/strong&gt; For more information, see &lt;a href="https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-http-webhook#authorization-keys"&gt;authorization keys&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Wait, what? Modify code, and rebuild the image? That sounds like a terribly slow and error-prone solution for testing your custom image locally. We will use the same image in Azure, with authorization working, so there must be a better way than modifying code and rebuilding the image. Digging deeper I found out that someone else was also asking about the same thing &lt;a href="https://github.com/Azure/azure-functions-host/issues/4147"&gt;here&lt;/a&gt;. The issue also contained a solution to my problem, see &lt;a href="https://github.com/Azure/azure-functions-host/issues/4147#issuecomment-477431016"&gt;this&lt;/a&gt;. The solution is to provide a custom &lt;code&gt;host.json&lt;/code&gt; to the container running locally. I found the easiest way to do this was to mount a volume from the host machine containing the custom &lt;code&gt;host.json&lt;/code&gt;. So, here's how I did this:&lt;/p&gt;
&lt;h2 id="enabling-shared-drives-with-docker-for-windows"&gt;1. Enabling Shared Drives with Docker for Windows&lt;/h2&gt;
&lt;p&gt;I use Windows as my primary OS, thus using Docker for Windows in order to use Docker. There are lots of guides on how to enable Shared Drives. There's even one over at &lt;a href="https://docs.microsoft.com/en-us/archive/blogs/wael-kdouh/enabling-drive-sharing-with-docker-for-windows"&gt;docs.microsoft.com&lt;/a&gt;. I however &lt;strong&gt;strongly&lt;/strong&gt; disagree with adding the local account into the &lt;code&gt;Administrators&lt;/code&gt; group. Instead I created a local account, removed it from the &lt;code&gt;Users&lt;/code&gt; group, and only gave the account access to the folder I wanted to share with Docker. In my case the folder I wanted to share with Docker was &lt;code&gt;C:\temp\docker&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id="create-custom-host.json"&gt;2. Create custom host.json&lt;/h2&gt;
&lt;p&gt;Next thing to do is to create a file called &lt;code&gt;host.json&lt;/code&gt; with the following content:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-json"&gt;{
  &amp;quot;masterKey&amp;quot;: {
    &amp;quot;name&amp;quot;: &amp;quot;master&amp;quot;,
    &amp;quot;value&amp;quot;: &amp;quot;test&amp;quot;,
    &amp;quot;encrypted&amp;quot;: false
  },
  &amp;quot;functionKeys&amp;quot;: [ ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The value of the &lt;code&gt;masterKey&lt;/code&gt; will be used as function key when testing the function later. I stored this file in folder &lt;code&gt;C:\temp\docker\keys&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id="testing-the-container-image-locally"&gt;3. Testing the container image locally&lt;/h2&gt;
&lt;p&gt;In order to test this out, we need to create an Azure Function using a custom container. So, we'll follow the tutorial I linked to in the beginning of this post.&lt;/p&gt;
&lt;p&gt;First, we'll create a new Functions project.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-powershell"&gt;func init LocalFunctionsProject --worker-runtime dotnet --docker
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then we'll add a function with a HTTP trigger&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-powershell"&gt;func new --name HttpExample --template &amp;quot;HTTP trigger&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then we'll build the image&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-powershell"&gt;docker build -t localfunctions:dev .
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And last, we'll run a container&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-powershell"&gt;docker run -v C:\temp\docker\keys:/azure-functions-host/Secrets `
 -e AzureWebJobsSecretStorageType=files `
 -e AzureFunctionsJobHost__Logging__Console__IsEnabled=true `
 -p 8080:80 -it localfunctions:dev
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;-v&lt;/code&gt; option will instruct Docker to mount a volume. In the example above it means that the folder &lt;code&gt;C:\temp\docker\keys&lt;/code&gt; on the host will be mounted at &lt;code&gt;/azure-functions-host/Secrets&lt;/code&gt; inside the container. This is a special folder that the Azure Functions runtime will use when we set the environment variable &lt;code&gt;AzureWebJobsSecretStorageType&lt;/code&gt; to &lt;code&gt;files&lt;/code&gt;. Remember that our custom &lt;code&gt;host.json&lt;/code&gt; we created earlier sits in the &lt;code&gt;C:\temp\docker\keys&lt;/code&gt; folder on the host machine.&lt;/p&gt;
&lt;p&gt;As a bonus, we'll also enable console logging by setting the environment variable &lt;code&gt;AzureFunctionsJobHost__Logging__Console__IsEnabled&lt;/code&gt; to &lt;code&gt;true&lt;/code&gt;. This will help us a lot if/when we need to troubleshoot any issues in our container.&lt;/p&gt;
&lt;p&gt;When the container is running, we can then test the function using e.g. cURL. First, we'll omit the function key (just to prove a point).&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;$ curl -s -i http://localhost:8080/api/HttpExample?name=foo
HTTP/1.1 401 Unauthorized
Date: Wed, 12 Feb 2020 21:13:23 GMT
Server: Kestrel
Content-Length: 0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And we'll get a &lt;code&gt;401 Unauthorized&lt;/code&gt;, just like we should. Now, we'll add the function key as request-header (remember the value of the function key was &lt;code&gt;test&lt;/code&gt;)&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;$ curl -s -i -H &amp;quot;x-functions-key:test&amp;quot; http://localhost:8080/api/HttpExample?name=foo
HTTP/1.1 200 OK
Date: Wed, 12 Feb 2020 21:17:05 GMT
Content-Type: text/plain; charset=utf-8
Server: Kestrel
Content-Length: 10

Hello, foo
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And now we'll get a &lt;code&gt;200 OK&lt;/code&gt; and a nice greeting from the server. Thanks for reading and hope you found this post useful.&lt;/p&gt;
</content>
		<summary>&lt;p&gt;Recently I had to create an Azure Function using a custom container. The reason was a client of mine did some really cool things using Puppeteer, and now they wanted to run this in an Azure Function. So, I went to &lt;a href="https://docs.microsoft.com"&gt;docs.microsoft.com&lt;/a&gt; and found a great &lt;a href="https://docs.microsoft.com/en-us/azure/azure-functions/functions-create-function-linux-custom-image?tabs=portal%2Cbash&amp;amp;pivots=programming-language-csharp"&gt;tutorial&lt;/a&gt; on how to create a function on Linux using a custom container. However, a little bit into the tutorial, in the &lt;a href="https://docs.microsoft.com/en-us/azure/azure-functions/functions-create-function-linux-custom-image?tabs=portal%2Cbash&amp;amp;pivots=programming-language-csharp"&gt;build the container image and test locally&lt;/a&gt; section, I noticed something very annoying, namely this:&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://martinbjorkstrom.com/posts/2018-11-29-creating-a-language-server" />
		<id>http://martinbjorkstrom.com/posts/2018-11-29-creating-a-language-server</id>
		<title>Creating a language server using .NET</title>
		<updated>2018-11-29T00:00:00Z</updated>
		<content>&lt;h2 id="background"&gt;Background&lt;/h2&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;A Language Server is meant to provide the language-specific smarts and communicate with development tools over a protocol that enables inter-process communication.&lt;/p&gt;
&lt;p&gt;The idea behind the Language Server Protocol (LSP) is to standardize the protocol for how such servers and development tools communicate. This way, a single Language Server can be re-used in multiple development tools, which in turn can support multiple languages with minimal effort.&lt;/p&gt;
&lt;p&gt;-- &lt;cite&gt;&lt;a href="https://microsoft.github.io/language-server-protocol/"&gt;Language Server Protocol&lt;/a&gt;&lt;/cite&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;LSP is a protocol originally developed by Microsoft for Visual Studio Code, which has evolved into an open standard that is supported by a wide range of editors and IDE's, including Visual Studio, Visual Studio Code, Eclipse, Atom, vim and emacs. The specification can be found on &lt;a href="https://github.com/Microsoft/language-server-protocol"&gt;GitHub&lt;/a&gt; and through the &lt;a href="https://microsoft.github.io/language-server-protocol/specification"&gt;official LSP website&lt;/a&gt;. Visual Studio Code docs include a sample on &lt;a href="https://code.visualstudio.com/docs/extensions/example-language-server"&gt;how to create a language server&lt;/a&gt; using Node.js®. But if you, like me, shouldn't be trusted with JavaScript, I have good news for you. In the rest of this blog post I'll walk you through the process of creating a Language Server supporting LSP using C# and .NET Core.&lt;/p&gt;
&lt;h2 id="language-server-implementation"&gt;Language Server Implementation&lt;/h2&gt;
&lt;p&gt;In this sample, we are going to create a Language Server for &lt;code&gt;*.csproj&lt;/code&gt; which enables autocomplete for &lt;code&gt;&amp;lt;PackageReference&amp;gt;&lt;/code&gt; elements. We are going to focus on integrating it with Visual Studio Code, but since LSP is supported by a wide range of IDE´s and editors, the effort for integrating it with any other editor should be minimal. To create a Language Server using .NET, we are going to use &lt;a href="https://www.nuget.org/packages/OmniSharp.Extensions.LanguageServer/"&gt;OmniSharp.Extensions.LanguageServer&lt;/a&gt;, which is a C# implementation of the LSP, authored by &lt;a href="https://github.com/david-driscoll"&gt;David Driscoll&lt;/a&gt; member of the &lt;a href="http://www.omnisharp.net/"&gt;OmniSharp&lt;/a&gt; team.&lt;/p&gt;
&lt;p&gt;For parsing XML, we are going to use &lt;a href="https://github.com/KirillOsenkov/XmlParser"&gt;Kirill Osenkov's XmlParser&lt;/a&gt;. You may think that using &lt;code&gt;XmlReader&lt;/code&gt; or &lt;code&gt;LINQ to XML&lt;/code&gt; would be sufficient, this is however not true. The first and most important rule of implementing a Language Server, is that you'll need an error tolerant parser as most of the time the code in the editor is incomplete and syntactically incorrect. Microsoft left some valuable notes &lt;a href="https://github.com/Microsoft/tolerant-php-parser/blob/master/docs/HowItWorks.md"&gt;here&lt;/a&gt; when they created the tolerant PHP parser, which currently backs PHP support in Visual Studio Code. Again, don't parse the files yourself (unless you know what you are doing), use a proper parser to get an Abstract Syntax Tree (AST).&lt;/p&gt;
&lt;p&gt;The full sample which we'll create in the rest of this blog post is available on GitHub at &lt;a href="https://github.com/mholo65/lsp-example/tree/blog-post"&gt;https://github.com/mholo65/lsp-example/tree/blog-post&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="creating-the-server"&gt;Creating the server&lt;/h3&gt;
&lt;p&gt;First, well start of by creating a new .NET Core console application.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-cmd"&gt;dotnet new console -n Server
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then we'll add the dependencies (the latter is just for the XmlParser)&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-cmd"&gt;dotnet add .\Server\Server.csproj package OmniSharp.Extensions.LanguageServer --version 0.10.0
dotnet add .\Server\Server.csproj package GuiLabs.Language.Xml --version 1.2.27
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First thing we'll need to do is to implement an &lt;code&gt;ITextDocumentSyncHandler&lt;/code&gt;. This is a handler which will handle the LSP Text Synchronization notifications &lt;a href="https://microsoft.github.io/language-server-protocol/specification#textDocument_didOpen"&gt;&lt;code&gt;didOpen&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://microsoft.github.io/language-server-protocol/specification#textDocument_didChange"&gt;&lt;code&gt;textDocument/didChange&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://microsoft.github.io/language-server-protocol/specification#textDocument_didSave"&gt;&lt;code&gt;textDocument/didSave&lt;/code&gt;&lt;/a&gt; and &lt;a href="https://microsoft.github.io/language-server-protocol/specification#textDocument_didClose"&gt;&lt;code&gt;textDocument/didClose&lt;/code&gt;&lt;/a&gt;. &lt;code&gt;textDocument/didChange&lt;/code&gt; is fundamental for a Language Server as this is where all document changes will end up as the end user is writing code. When registering the &lt;code&gt;textDocument/didChange&lt;/code&gt; notification handler, we'll have the possibility to select either &lt;code&gt;Full&lt;/code&gt; or &lt;code&gt;Incremental&lt;/code&gt; as &lt;code&gt;syncKind&lt;/code&gt;. For simplicity, in this sample, we'll register to receive the full document text on every text change. In real world scenarios, for performance reasons, I'd strongly suggest registering for receiving incremental updates.&lt;/p&gt;
&lt;p&gt;To have the buffer available for other handlers, we'll create a &lt;code&gt;BufferManager&lt;/code&gt; whose main task is to always contain the latest version of a document. For simplicity, in this sample, we'll just use a &lt;code&gt;ConcurrentDictionary&lt;/code&gt; as the backing store which will just contain the full text for each document (with the document path as key). For real world scenarios, you'd most probably want to also parse the document upon each change and publish diagnostics as they occur (see &lt;a href="https://microsoft.github.io/language-server-protocol/specification#textDocument_publishDiagnostics"&gt;&lt;code&gt;textDocument/publishDiagnostics&lt;/code&gt;&lt;/a&gt; and &lt;a href="https://github.com/OmniSharp/csharp-language-server-protocol/blob/v0.10.0/src/Protocol/Document/Server/PublishDiagnosticsExtensions.cs"&gt;&lt;code&gt;PublishDiagnosticsExtensions.cs&lt;/code&gt;&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;&lt;em&gt;BufferManager.cs&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-csharp"&gt;class BufferManager
{
    private ConcurrentDictionary&amp;lt;string, Buffer&amp;gt; _buffers = new ConcurrentDictionary&amp;lt;string, Buffer&amp;gt;();

    public void UpdateBuffer(string documentPath, Buffer buffer)
    {
        _buffers.AddOrUpdate(documentPath, buffer, (k, v) =&amp;gt; buffer);
    }

    public Buffer GetBuffer(string documentPath)
    {
        return _buffers.TryGetValue(documentPath, out var buffer) ? buffer : null;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;TextDocumentSyncHandler.cs&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-csharp"&gt;class TextDocumentSyncHandler : ITextDocumentSyncHandler
{
    private readonly ILanguageServer _router;
    private readonly BufferManager _bufferManager;

    private readonly DocumentSelector _documentSelector = new DocumentSelector(
        new DocumentFilter()
        {
            Pattern = &amp;quot;**/*.csproj&amp;quot;
        }
    );

    private SynchronizationCapability _capability;

    public TextDocumentSyncHandler(ILanguageServer router, BufferManager bufferManager)
    {
        _router = router;
        _bufferManager = bufferManager;
    }

    public TextDocumentSyncKind Change { get; } = TextDocumentSyncKind.Full;

    public TextDocumentChangeRegistrationOptions GetRegistrationOptions()
    {
        return new TextDocumentChangeRegistrationOptions()
        {
            DocumentSelector = _documentSelector,
            SyncKind = Change
        };
    }

    public TextDocumentAttributes GetTextDocumentAttributes(Uri uri)
    {
        return new TextDocumentAttributes(uri, &amp;quot;xml&amp;quot;);
    }

    public Task&amp;lt;Unit&amp;gt; Handle(DidChangeTextDocumentParams request, CancellationToken cancellationToken)
    {
        var documentPath = request.TextDocument.Uri.ToString();
        var text = request.ContentChanges.FirstOrDefault()?.Text;

        _bufferManager.UpdateBuffer(documentPath, new StringBuffer(text));

        _router.Window.LogInfo($&amp;quot;Updated buffer for document: {documentPath}\n{text}&amp;quot;);

        return Unit.Task;
    }

    public Task&amp;lt;Unit&amp;gt; Handle(DidOpenTextDocumentParams request, CancellationToken cancellationToken)
    {
        _bufferManager.UpdateBuffer(request.TextDocument.Uri.ToString(), new StringBuffer(request.TextDocument.Text));
        return Unit.Task;
    }
    ...
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Last thing we'll need to do is to configure the Language Server and start it up in &lt;code&gt;Program.cs&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-csharp"&gt;class Program
{
    static async Task Main(string[] args)
    {
        var server = await LanguageServer.From(options =&amp;gt;
            options
                .WithInput(Console.OpenStandardInput())
                .WithOutput(Console.OpenStandardOutput())
                .WithLoggerFactory(new LoggerFactory())
                .AddDefaultLoggingProvider()
                .WithMinimumLogLevel(LogLevel.Trace)
                .WithServices(ConfigureServices)
                .WithHandler&amp;lt;TextDocumentSyncHandler&amp;gt;()
             );

        await server.WaitForExit;
    }

    static void ConfigureServices(IServiceCollection services)
    {
        services.AddSingleton&amp;lt;BufferManager&amp;gt;();
     }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="creating-the-completion-handler"&gt;Creating the Completion Handler&lt;/h3&gt;
&lt;p&gt;Now, when we are able to react on document changes, we are able to implement handlers for any Language Feature of the LSP. In this sample we'll implement a handler for the &lt;a href="https://microsoft.github.io/language-server-protocol/specification#textDocument_completion"&gt;&lt;code&gt;textDocument/completion&lt;/code&gt;&lt;/a&gt; request. This is easily done in .NET by implementing the &lt;code&gt;ICompletionHandler&lt;/code&gt; interface. When registering the completion handler, we'll have the possibility to also register a &lt;a href="https://microsoft.github.io/language-server-protocol/specification#completionItem_resolve"&gt;&lt;code&gt;completionItem/resolve&lt;/code&gt;&lt;/a&gt; handler (&lt;code&gt;ICompletionResolveHandler&lt;/code&gt;). For simplicity, in this sample, we'll not use a completion resolver handler. This might be useful in real world scenarios when you'll want to return a list of completion items as quickly as possible, and later return additional information about the completion items upon request. E.g. with &lt;code&gt;&amp;lt;PackageReference&amp;gt;&lt;/code&gt; completions, we could return the matching package ID's directly, and resolve package description upon request in the resolve handler.&lt;/p&gt;
&lt;p&gt;To provide autocomplete for NuGet packages, we'll use the &lt;a href="https://docs.microsoft.com/en-us/nuget/api/search-autocomplete-service-resource"&gt;Autcomplete API&lt;/a&gt; which is part of the &lt;a href="https://docs.microsoft.com/en-us/nuget/api/overview"&gt;NuGet V3 API&lt;/a&gt;. This exposes a simple service to search for package ID's and enumerating package versions.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;CompletionHandler.cs&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-csharp"&gt;class CompletionHandler : ICompletionHandler
{
    private const string PackageReferenceElement = &amp;quot;PackageReference&amp;quot;;
    private const string IncludeAttribute = &amp;quot;Include&amp;quot;;
    private const string VersionAttribute = &amp;quot;Version&amp;quot;;

    private readonly ILanguageServer _router;
    private readonly BufferManager _bufferManager;
    private readonly NuGetAutoCompleteService _nuGetService;

    private readonly DocumentSelector _documentSelector = new DocumentSelector(
        new DocumentFilter()
        {
            Pattern = &amp;quot;**/*.csproj&amp;quot;
        }
    );

    private CompletionCapability _capability;

    public CompletionHandler(ILanguageServer router, BufferManager bufferManager, NuGetAutoCompleteService nuGetService)
    {
        _router = router;
        _bufferManager = bufferManager;
        _nuGetService = nuGetService;
    }

    public CompletionRegistrationOptions GetRegistrationOptions()
    {
        return new CompletionRegistrationOptions
        {
            DocumentSelector = _documentSelector,
            ResolveProvider = false
        };
    }

    public async Task&amp;lt;CompletionList&amp;gt; Handle(CompletionParams request, CancellationToken cancellationToken)
    {
        var documentPath = request.TextDocument.Uri.ToString();
        var buffer = _bufferManager.GetBuffer(documentPath);

        if (buffer == null)
        {
            return new CompletionList();
        }

        var syntaxTree = Parser.Parse(buffer);

        var position = GetPosition(buffer.GetText(0, buffer.Length),
            (int)request.Position.Line,
            (int)request.Position.Character);

        var node = syntaxTree.FindNode(position);

        var attribute = node.AncestorNodes().OfType&amp;lt;XmlAttributeSyntax&amp;gt;().FirstOrDefault();
        if (attribute != null &amp;amp;&amp;amp; node.ParentElement.Name.Equals(PackageReferenceElement))
        {
            if (attribute.Name.Equals(IncludeAttribute))
            {
                var completions = await _nuGetService.GetPackages(attribute.Value);

                var diff = position - attribute.ValueNode.Start;

                return new CompletionList(completions.Select(x =&amp;gt; new CompletionItem
                {
                    Label = x,
                    Kind = CompletionItemKind.Reference,
                    TextEdit = new TextEdit
                    {
                        NewText = x,
                        Range = new Range(
                            new Position
                            {
                                Line = request.Position.Line,
                                Character = request.Position.Character - diff + 1
                            }, new Position
                            {
                                Line = request.Position.Line,
                                Character = request.Position.Character - diff + attribute.ValueNode.Width - 1
                            })
                    }
                }), isIncomplete: completions.Count &amp;gt; 1);
            }
            else if (attribute.Name.Equals(VersionAttribute))
            {
                var includeNode = node.ParentElement.Attributes.FirstOrDefault(x =&amp;gt; x.Name.Equals(IncludeAttribute));

                if (includeNode != null &amp;amp;&amp;amp; !string.IsNullOrEmpty(includeNode.Value))
                {
                    var versions = await _nuGetService.GetPackageVersions(includeNode.Value, attribute.Value);

                    var diff = position - attribute.ValueNode.Start;

                    return new CompletionList(versions.Select(x =&amp;gt; new CompletionItem
                    {
                        Label = x,
                        Kind = CompletionItemKind.Reference,
                        TextEdit = new TextEdit
                        {
                            NewText = x,
                            Range = new Range(
                                new Position
                                {
                                    Line = request.Position.Line,
                                    Character = request.Position.Character - diff + 1
                                }, new Position
                                {
                                    Line = request.Position.Line,
                                    Character = request.Position.Character - diff + attribute.ValueNode.Width - 1
                                })
                        }
                    }));
                }
            }
        }

        return new CompletionList();
    }

    private static int GetPosition(string buffer, int line, int col)
    {
        var position = 0;
        for (var i = 0; i &amp;lt; line; i++)
        {
            position = buffer.IndexOf('\n', position) + 1;
        }
        return position + col;
    }

    public void SetCapability(CompletionCapability capability)
    {
        _capability = capability;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;NuGetAutoCompleteService.cs&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-csharp"&gt;class NuGetAutoCompleteService
{
    private HttpClient _client = new HttpClient();

    public async Task&amp;lt;IReadOnlyCollection&amp;lt;string&amp;gt;&amp;gt; GetPackages(string query)
    {
        var response = await _client.GetStringAsync($&amp;quot;https://api-v2v3search-0.nuget.org/autocomplete?q={query}&amp;quot;);
        return JObject.Parse(response)[&amp;quot;data&amp;quot;].ToObject&amp;lt;List&amp;lt;string&amp;gt;&amp;gt;();
    }

    public async Task&amp;lt;IReadOnlyCollection&amp;lt;string&amp;gt;&amp;gt; GetPackageVersions(string package, string version)
    {
        var response = await _client.GetStringAsync($&amp;quot;https://api-v2v3search-0.nuget.org/autocomplete?id={package}&amp;quot;);
        return JObject.Parse(response)[&amp;quot;data&amp;quot;].ToObject&amp;lt;List&amp;lt;string&amp;gt;&amp;gt;();
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And last we'll just hook up our completion handler and the NuGet completion service in &lt;code&gt;Program.cs&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-csharp"&gt;
class Program
{
    static async Task Main(string[] args)
    {
        var server = await LanguageServer.From(options =&gt;
            options
                .WithInput(Console.OpenStandardInput())
                .WithOutput(Console.OpenStandardOutput())
                .WithLoggerFactory(new LoggerFactory())
                .AddDefaultLoggingProvider()
                .WithMinimumLogLevel(LogLevel.Trace)
                .WithServices(ConfigureServices)
                .WithHandler&amp;lt;TextDocumentSyncHandler&amp;gt;()
                &lt;span style="background-color: #FFFF00"&gt;&lt;b&gt;.WithHandler&amp;lt;CompletionHandler&amp;gt;()&lt;/b&gt;&lt;/span&gt;
            );

        await server.WaitForExit;
    }

    static void ConfigureServices(IServiceCollection services)
    {
        services.AddSingleton&amp;lt;BufferManager&amp;gt;();
        &lt;span style="background-color: #FFFF00"&gt;&lt;b&gt;services.AddSingleton&amp;lt;NuGetAutoCompleteService&amp;gt;();&lt;/b&gt;&lt;/span&gt;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="creating-the-client"&gt;Creating the client&lt;/h3&gt;
&lt;p&gt;Creating a Visual Studio Code Extension, aka the LSP client which utilizes our Language Server, is quite straightforward. We need to specify an activation event in &lt;code&gt;package.json&lt;/code&gt; and then create a LSP client which starts the language server in our &lt;code&gt;activate&lt;/code&gt; function. In this sample, we'll activate the extension when a XML file is opened and then configure our LSP client to synchronize any changes made to &lt;code&gt;.csproj&lt;/code&gt; files with the Language Server.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;package.json&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-json"&gt;{
    &amp;quot;name&amp;quot;: &amp;quot;client&amp;quot;,
    &amp;quot;displayName&amp;quot;: &amp;quot;Client&amp;quot;,
    &amp;quot;description&amp;quot;: &amp;quot;Example LSP client&amp;quot;,
    &amp;quot;publisher&amp;quot;: &amp;quot;mholo65&amp;quot;,
    &amp;quot;version&amp;quot;: &amp;quot;0.0.1&amp;quot;,
    &amp;quot;engines&amp;quot;: {
        &amp;quot;vscode&amp;quot;: &amp;quot;^1.29.0&amp;quot;
    },
    &amp;quot;categories&amp;quot;: [
        &amp;quot;Other&amp;quot;
    ],
    &amp;quot;activationEvents&amp;quot;: [
        &amp;quot;onLanguage:xml&amp;quot;
    ],
    &amp;quot;main&amp;quot;: &amp;quot;./out/extension&amp;quot;,
    &amp;quot;contributes&amp;quot;: {},
    ...
}

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;extension.ts&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-typescript"&gt;'use strict';

import { workspace, Disposable, ExtensionContext } from 'vscode';
import { LanguageClient, LanguageClientOptions, SettingMonitor, ServerOptions, TransportKind, InitializeParams } from 'vscode-languageclient';
import { Trace } from 'vscode-jsonrpc';

export function activate(context: ExtensionContext) {

    // The server is implemented in node
    let serverExe = 'dotnet';

    // If the extension is launched in debug mode then the debug server options are used
    // Otherwise the run options are used
    let serverOptions: ServerOptions = {
        run: { command: serverExe, args: ['/path/to/Server.dll'] },
        debug: { command: serverExe, args: ['/path/to/Server.dll'] }
    }

    // Options to control the language client
    let clientOptions: LanguageClientOptions = {
        // Register the server for plain text documents
        documentSelector: [
            {
                pattern: '**/*.csproj',
            }
        ],
        synchronize: {
            // Synchronize the setting section 'languageServerExample' to the server
            configurationSection: 'languageServerExample',
            fileEvents: workspace.createFileSystemWatcher('**/*.csproj')
        },
    }

    // Create the language client and start the client.
    const client = new LanguageClient('languageServerExample', 'Language Server Example', serverOptions, clientOptions);
    client.trace = Trace.Verbose;
    let disposable = client.start();

    // Push the disposable to the context's subscriptions so that the
    // client can be deactivated on extension deactivation
    context.subscriptions.push(disposable);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="profit"&gt;Profit&lt;/h3&gt;
&lt;p&gt;If you've read this far and maybe checked out the code in the &lt;a href="https://github.com/mholo65/lsp-example/tree/blog-post"&gt;sample repository&lt;/a&gt;, you should have a Visual Studio Code extension which adds autocomplete functionality for package references in &lt;code&gt;.csproj&lt;/code&gt; files, just like in the tweet below.&lt;/p&gt;
&lt;blockquote class="twitter-tweet" data-conversation="none" data-lang="en"&gt;&lt;p lang="en" dir="ltr"&gt;Now using XmlParser. Code&amp;#39;s much cleaner, and it was a piece of cake to also get autocomplete for version. Btw, source is here &lt;a href="https://t.co/cUnKGliC4T"&gt;https://t.co/cUnKGliC4T&lt;/a&gt; &lt;a href="https://t.co/ac3LizlY4S"&gt;pic.twitter.com/ac3LizlY4S&lt;/a&gt;&lt;/p&gt;&amp;mdash; Martin Björkström (&amp;#64;mholo65) &lt;a href="https://twitter.com/mholo65/status/1066815193718669313?ref_src=twsrc%5Etfw"&gt;November 25, 2018&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h2 id="credits-and-resources"&gt;Credits and Resources&lt;/h2&gt;
&lt;p&gt;If you think &lt;code&gt;&amp;lt;PackageReference&amp;gt;&lt;/code&gt; autocomplete is cool, then you should definitely check out &lt;a href="https://github.com/tintoy"&gt;Adam Friedman's&lt;/a&gt; &lt;a href="https://marketplace.visualstudio.com/items?itemName=tintoy.msbuild-project-tools"&gt;MSBuild project tools&lt;/a&gt; extension for Visual Studio Code. The extension includes &lt;code&gt;&amp;lt;PackageReference&amp;gt;&lt;/code&gt; autocomplete and a bunch of other useful tools for MSBuild project files. The source for the Language Server (which uses the same LSP libraries as used in this sample) is available on &lt;a href="https://github.com/tintoy/msbuild-project-tools-server"&gt;GitHub&lt;/a&gt;. Other examples of language servers implemented in .NET, using the same awesome &lt;a href="https://www.nuget.org/packages/OmniSharp.Extensions.LanguageServer/"&gt;OmniSharp.Extensions.LanguageServer&lt;/a&gt; libraries are &lt;a href="https://github.com/aspnet/Razor.VSCode/tree/master/src/Microsoft.AspNetCore.Razor.LanguageServer"&gt;Razor for VSCode&lt;/a&gt; and &lt;a href="https://github.com/OmniSharp/omnisharp-roslyn/tree/master/src/OmniSharp.LanguageServerProtocol"&gt;LSP support for OmniSharp Roslyn&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you're curious about LSP support in .NET or have additional questions, please come hang out with Adam, David and me in the &lt;a href="https://omnisharp.herokuapp.com/"&gt;OmniSharp Slack&lt;/a&gt; &lt;code&gt;#lsp&lt;/code&gt; channel.&lt;/p&gt;
</content>
		<summary>&lt;p&gt;A Language Server is meant to provide the language-specific smarts and communicate with development tools over a protocol that enables inter-process communication.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://martinbjorkstrom.com/posts/2018-10-15-dissecting-sf-mesh-vs-publish" />
		<id>http://martinbjorkstrom.com/posts/2018-10-15-dissecting-sf-mesh-vs-publish</id>
		<title>Dissecting the Azure Service Fabric Mesh Right-Click Publish</title>
		<updated>2018-10-15T00:00:00Z</updated>
		<content>&lt;h1 id="because-friends-dont-let-friends-do-right-click-publish"&gt;Because friends don't let friends do right-click publish&lt;/h1&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;This is not a post on why you should not do right-click publish, but rather a post on how to avoid it when working with Azure Service Fabric Mesh. If you want an answer for the why part, please read &lt;a href="https://damianbrady.com.au/2018/02/01/friends-dont-let-friends-right-click-publish/"&gt;Damian Brady's blog post&lt;/a&gt; on the subject.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;If you've ever looked at the &lt;a href="https://docs.microsoft.com/en-us/azure/service-fabric-mesh/"&gt;Azure Service Fabric Mesh tutorials&lt;/a&gt;, you've probably noticed that they only show you how to do right-click publish (or deploy pre-made ARM-templates). In order to understand how to avoid right-click publish, we'll need to understand what right-click publish does. Therefore, in this blog post we're going to dissect the right-click publish feature of &lt;a href="https://marketplace.visualstudio.com/items?itemName=ms-azuretools.ServiceFabricMesh"&gt;Service Fabric Mesh Tools for Visual Studio&lt;/a&gt;. Before I started any practical work, which eventually lead to this blog post, I had a rough idea on how to bypass right-click publish when working with Azure Service Fabric Mesh solutions and Visual Studio, namely:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Create docker images for each service in the application&lt;/li&gt;
&lt;li&gt;Push the docker images to an Azure Container Registry&lt;/li&gt;
&lt;li&gt;Generate an ARM template&lt;/li&gt;
&lt;li&gt;Deploy the Azure Service Fabric Mesh application using the generated ARM template&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I knew that the Service Fabric Mesh Tools was accountable for some of the &amp;quot;magic&amp;quot;, while the &lt;a href="https://www.nuget.org/packages/Microsoft.VisualStudio.Azure.SFApp.Targets"&gt;Service Fabric MSBuild targets&lt;/a&gt; was accountable the rest. Because I'm more comfortable with debugging MSBuild than reverse-engineering Visual Studio extensions, the natural starting point was investigating the MSBuild targets and see how far it would take me.&lt;/p&gt;
&lt;p&gt;In the following sections I will use the &lt;code&gt;todolistapp&lt;/code&gt; sample located &lt;a href="https://github.com/Azure-Samples/service-fabric-mesh/tree/c3da5474a67d635565a092ed9090442888142f9f/src/todolistapp"&gt;here&lt;/a&gt;. So if you'd like to follow along, make sure you clone the &lt;a href="https://github.com/Azure-Samples/service-fabric-mesh"&gt;Service Fabric Mesh Samples repository&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="investigating-msbuild-targets"&gt;Investigating MSBuild Targets&lt;/h2&gt;
&lt;p&gt;There are many ways to debug MSBuild, one  way to find all targets is to use the preprocess switch with MSBuild. MSBuild help says the following about the preprocess switch:&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;/preprocess[:file]
Creates a single, aggregated project file by
inlining all the files that would be imported during a
build, with their boundaries marked. This can be
useful for figuring out what files are being imported
and from where, and what they will contribute to
the build. By default the output is written to
the console window. If the path to an output file
is provided that will be used instead.
(Short form: /pp)
Example:
/pp:out.txt&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;We run the following command and then inspect the &lt;code&gt;out.xml&lt;/code&gt; file.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-cmd"&gt;msbuild /r /pp:out.xml todolistapp\todolistapp.sfaproj
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;While inspecting the &lt;code&gt;out.xml&lt;/code&gt; file, we'll find two targets which are of special interest; &lt;code&gt;SFAppBuildApplication&lt;/code&gt; and &lt;code&gt;SFAppPackageApplication&lt;/code&gt;. I also remember seeing these two targets when skimming through the Service Fabric Mesh Tools logs in Visual Studio.&lt;/p&gt;
&lt;h2 id="building-service-fabric-mesh-application"&gt;Building Service Fabric Mesh Application&lt;/h2&gt;
&lt;p&gt;Let's try out the first target then, run:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-cmd"&gt;msbuild /r /t:todolistapp:SFAppBuildApplication /p:Configuration=Release;Platform=&amp;quot;Any CPU&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the logs, we can see that the above target will find all services and build docker images, which is exactly what we want! We can see that it is naming and tagging our images like &lt;code&gt;webfrontend:dev&lt;/code&gt; and &lt;code&gt;todoservice:dev&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-cmd"&gt;  docker build -f &amp;quot;C:\Users\mb\src\gh\service-fabric-mesh\src\todolistapp\WebFrontEnd\Dockerfile&amp;quot; -t webfrontend:dev &amp;quot;C:\Users\mb\src\gh\service-fabric-mesh\src\todolistapp&amp;quot;
  Sending build context to Docker daemon   3.52MB

  Step 1/16 : FROM microsoft/dotnet:2.1-aspnetcore-runtime-nanoserver-sac2016 AS base
   ---&amp;gt; b1d6aab503b4
   ---&amp;gt; d35f8074bc6a

  ...

  Step 16/16 : ENTRYPOINT [&amp;quot;dotnet&amp;quot;, &amp;quot;WebFrontEnd.dll&amp;quot;]
   ---&amp;gt; Running in 95c5976daa00
  Removing intermediate container 95c5976daa00
   ---&amp;gt; 915e93d027a6
  Successfully built 915e93d027a6
  Successfully tagged webfrontend:dev
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above step solved the first issue for us, it created docker images for each service in the application. While we could have searched for all dockerfile's ourselves and run &lt;code&gt;docker build&lt;/code&gt;, I find the MSBuild target a little more helpful.&lt;/p&gt;
&lt;h2 id="push-the-docker-images-to-an-azure-container-registry"&gt;Push the docker images to an Azure Container Registry&lt;/h2&gt;
&lt;p&gt;Next thing to do is to push our newly created docker images to a container registry. If you don't already have an Azure Container Registry, please follow the steps &lt;a href="https://docs.microsoft.com/en-us/azure/container-registry/container-registry-get-started-portal"&gt;here&lt;/a&gt; to create one and obtain the access keys (login server, username and password). Now, to push our local docker images to the Azure Container Registry, we'll just follow some of the examples found &lt;a href="https://docs.microsoft.com/en-us/azure/container-registry/container-registry-get-started-docker-cli"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;First we'll use &lt;a href="https://docs.docker.com/engine/reference/commandline/tag/"&gt;docker tag&lt;/a&gt; to create aliases of our local images (replace &lt;code&gt;todolistappacr&lt;/code&gt; with the name of your container registry):&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-cmd"&gt;docker tag webfrontend:dev todolistappacr.azurecr.io/webfrontend:1.0
docker tag todoservice:dev todolistappacr.azurecr.io/todoservice:1.0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, we'll need to login to the Azure Container Registry and push our images (replace &lt;code&gt;todolistappacr&lt;/code&gt;with the name of your container registry).&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-cmd"&gt;docker login todolistappacr.azurecr.io -u username -p password
docker push todolistappacr.azurecr.io/webfrontend:1.0
docker push todolistappacr.azurecr.io/todoservice:1.0
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="packaging-service-fabric-mesh-application"&gt;Packaging Service Fabric Mesh Application&lt;/h2&gt;
&lt;p&gt;Now that we have pushed the docker images to our container registry, we can start preparing the Azure Service Fabric Mesh application. For this, we'll call &lt;code&gt;msbuild&lt;/code&gt; with the &lt;code&gt;SFAppPackageApplication&lt;/code&gt; target.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-cmd"&gt;msbuild /r /t:todolistapp:SFAppPackageApplication /p:Configuration=Release;Platform=&amp;quot;Any CPU&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above target will find all &lt;code&gt;yaml&lt;/code&gt;-files and pass them to a tool called &lt;code&gt;SfSbzYamlMerge.exe&lt;/code&gt;. The tool will merge all &lt;code&gt;yaml&lt;/code&gt;-files and output a &lt;code&gt;json&lt;/code&gt;-file (&lt;code&gt;merged-arm_rp.json&lt;/code&gt;). This &lt;code&gt;json&lt;/code&gt;-file is the ARM (Azure Resource Manager) template we are going to use for publishing our Service Fabric Mesh application to Azure. If we try to diff the &lt;code&gt;merged-arm_rp.json&lt;/code&gt; file to the one Visual Studio leaves behind after doing right-click publish, we'll notice some differences.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-diff"&gt;--- bin/Release/SBZPkg/merged-arm_rp.json       2018-10-11 21:46:46.967348000 +0300
+++ bin/Debug/SBZPkg/merged-arm_rp.json 2018-10-11 17:38:36.497734800 +0300
&amp;#64;&amp;#64; -8,6 +8,10 &amp;#64;&amp;#64;
       &amp;quot;metadata&amp;quot;: {
         &amp;quot;description&amp;quot;: &amp;quot;Location of the resources.&amp;quot;
       }
+    },
+    &amp;quot;registryPassword&amp;quot;: {
+      &amp;quot;defaultValue&amp;quot;: &amp;quot;&amp;quot;,
+      &amp;quot;type&amp;quot;: &amp;quot;SecureString&amp;quot;
     }
   },
   &amp;quot;resources&amp;quot;: [
&amp;#64;&amp;#64; -29,7 +33,7 &amp;#64;&amp;#64;
               &amp;quot;codePackages&amp;quot;: [
                 {
                   &amp;quot;name&amp;quot;: &amp;quot;WebFrontEnd&amp;quot;,
-                  &amp;quot;image&amp;quot;: &amp;quot;webfrontend:dev&amp;quot;,
+                  &amp;quot;image&amp;quot;: &amp;quot;todolistappacr.azurecr.io/webfrontend:20181011173823&amp;quot;,
                   &amp;quot;endpoints&amp;quot;: [
                     {
                       &amp;quot;name&amp;quot;: &amp;quot;WebFrontEndListener&amp;quot;,
&amp;#64;&amp;#64; -55,6 +59,11 &amp;#64;&amp;#64;
                       &amp;quot;cpu&amp;quot;: 0.5,
                       &amp;quot;memoryInGB&amp;quot;: 1.0
                     }
+                  },
+                  &amp;quot;imageRegistryCredential&amp;quot;: {
+                    &amp;quot;server&amp;quot;: &amp;quot;todolistappacr.azurecr.io&amp;quot;,
+                    &amp;quot;username&amp;quot;: &amp;quot;todolistappacr&amp;quot;,
+                    &amp;quot;password&amp;quot;: &amp;quot;[parameters('registryPassword')]&amp;quot;
                   }
                 }
               ],
&amp;#64;&amp;#64; -74,7 +83,7 &amp;#64;&amp;#64;
               &amp;quot;codePackages&amp;quot;: [
                 {
                   &amp;quot;name&amp;quot;: &amp;quot;ToDoService&amp;quot;,
-                  &amp;quot;image&amp;quot;: &amp;quot;todoservice:dev&amp;quot;,
+                  &amp;quot;image&amp;quot;: &amp;quot;todolistappacr.azurecr.io/todoservice:20181011173823&amp;quot;,
                   &amp;quot;endpoints&amp;quot;: [
                     {
                       &amp;quot;name&amp;quot;: &amp;quot;ToDoServiceListener&amp;quot;,
&amp;#64;&amp;#64; -92,6 +101,11 &amp;#64;&amp;#64;
                       &amp;quot;cpu&amp;quot;: 0.5,
                       &amp;quot;memoryInGB&amp;quot;: 1.0
                     }
+                  },
+                  &amp;quot;imageRegistryCredential&amp;quot;: {
+                    &amp;quot;server&amp;quot;: &amp;quot;todolistappacr.azurecr.io&amp;quot;,
+                    &amp;quot;username&amp;quot;: &amp;quot;todolistappacr&amp;quot;,
+                    &amp;quot;password&amp;quot;: &amp;quot;[parameters('registryPassword')]&amp;quot;
                   }
                 }
               ],
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The ARM template generated by Visual Studio takes a parameter called &lt;code&gt;registryPassword&lt;/code&gt; and the images in the code packages for each service seems to point at our Azure Container Registry, while our ARM template just uses &lt;code&gt;todoservice:dev&lt;/code&gt; (the default name and tag created by the MSBuild targets). The Visual Studio generated ARM template also has a &lt;code&gt;imageRegistryCredential&lt;/code&gt; in each code package. We'll need to update our ARM template with the changes seen above. Make sure you use the correct registry server and username, also make sure to use the same tag of the docker image as we used when we pushed the images (we used &lt;code&gt;1.0&lt;/code&gt; in the example previously. So change &lt;code&gt;20181011173823&lt;/code&gt; to &lt;code&gt;1.0&lt;/code&gt;).&lt;/p&gt;
&lt;h2 id="deploy-the-azure-service-fabric-mesh-application-using-the-generated-arm-template"&gt;Deploy the Azure Service Fabric Mesh application using the generated ARM template&lt;/h2&gt;
&lt;p&gt;Now that we have created our ARM template, we are ready to publish our Service Fabric Mesh application to Azure. We'll use the same commands as can be found in the &lt;a href="https://docs.microsoft.com/en-us/azure/service-fabric-mesh/service-fabric-mesh-tutorial-template-deploy-app"&gt;Service Fabric Mesh Tutorial&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;First, Login to Azure&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-cmd"&gt;az login
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, create a resource group&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-cmd"&gt;az group create -l eastus -n todolistapp-rg
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Last, create the deployment (replace &lt;code&gt;password&lt;/code&gt; with the password to your Azure Container Registry).&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-cmd"&gt;az mesh deployment create --resource-group todolistapp-rg --template-file todolistapp\bin\Release\SBZPkg\merged-arm_rp.json --name todolistapp --parameters location=eastus registryPassword=password
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You may follow the progress of the deployment in Azure Portal, but after a couple of minutes you should see that the application have been successfully deployed.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-cmd"&gt;Deploying . . .
application todolistapp has been deployed successfully on network todolistappNetwork with public ip address 40.76.208.91
To recieve additional information run the following to get the status of the application deployment.
az mesh app show --resource-group todolistapp-rg --name todolistapp
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, just open a browser and head over to the IP address and see your application in action. Make sure to also specify the correct port. The sample use &lt;code&gt;20006&lt;/code&gt; as default, so in the above example I'd open my browser and go to &lt;a href="http://40.76.208.91:20006/."&gt;http://40.76.208.91:20006/.&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;While we got pretty far by just using the msbuild targets located in &lt;code&gt;Microsoft.VisualStudio.Azure.SFApp.Targets&lt;/code&gt; we still need to do some manual work with pushing docker images and modifying the ARM-template. AFAIK, the msbuild targets don't understand publish profile &lt;code&gt;yaml&lt;/code&gt;-files as these are solely intended to be used with the Visual Studio Tooling (ie. right-click deploy). We still have some work to do before we can deploy Service Fabric Mesh applications from our CI/CD pipeline. However, if it can be documented, it can be automated. Therefore, stay tuned for a follow up blog post on how to automate the above steps with &lt;a href="https://cakebuild.net/"&gt;Cake&lt;/a&gt;.&lt;/p&gt;
</content>
		<summary>&lt;p&gt;This is not a post on why you should not do right-click publish, but rather a post on how to avoid it when working with Azure Service Fabric Mesh. If you want an answer for the why part, please read &lt;a href="https://damianbrady.com.au/2018/02/01/friends-dont-let-friends-right-click-publish/"&gt;Damian Brady's blog post&lt;/a&gt; on the subject.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://martinbjorkstrom.com/posts/2018-10-09-open-sourcing-alpha-beta" />
		<id>http://martinbjorkstrom.com/posts/2018-10-09-open-sourcing-alpha-beta</id>
		<title>Open Sourcing Alpha-Beta</title>
		<updated>2018-10-09T00:00:00Z</updated>
		<content>&lt;p&gt;&lt;a href="https://github.com/mholo65/alpha-beta"&gt;Alpha-Beta&lt;/a&gt; is a simple learning game I made for my children about a year ago that I'm now open sourcing. It's a fun way for kids to learn to write words, and locate keys on the keyboard. The game picks a random word from a list for the user to type. It uses Azure cognitive services like &lt;a href="https://docs.microsoft.com/en-us/azure/cognitive-services/bing-image-search/"&gt;Bing Image Search&lt;/a&gt; for searching related images and &lt;a href="https://docs.microsoft.com/en-us/azure/cognitive-services/speech/home"&gt;Bing Speech&lt;/a&gt; for reading the word out loud. See it in action below:&lt;/p&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/mholo65/alpha-beta/master/media/demo.gif" class="img-fluid" alt="alpha-beta" /&gt;&lt;/p&gt;
&lt;p&gt;The game is multilingual, just specify the locale in &lt;code&gt;app.config&lt;/code&gt; and you're good to go. It &lt;em&gt;should&lt;/em&gt;  support all the locales that are supported by Bing Speech (see list &lt;a href="https://docs.microsoft.com/en-us/azure/cognitive-services/Speech/api-reference-rest/bingvoiceoutput#SupLocales"&gt;here&lt;/a&gt;), although  I've only tested &lt;code&gt;fi-FI&lt;/code&gt;, &lt;code&gt;sv-SE&lt;/code&gt;, &lt;code&gt;en-US&lt;/code&gt; and &lt;code&gt;en-GB&lt;/code&gt;. I also tried to make it super simple for my non-programming significant other to add and remove words used in the game. Currently it picks the words from a &lt;code&gt;txt&lt;/code&gt;-file, where each words used are separated by a new line. I know that there are lots of similar games out there, but since my kids are swedish speaking, it was hard to find something good. Creating Alpha-Beta also got me to do some hands-on work with Azure cognitive services, which was a pleasant acquaintance.&lt;/p&gt;
&lt;p&gt;Source can be found &lt;a href="https://github.com/mholo65/alpha-beta"&gt;here&lt;/a&gt;. It currently only runs on Windows, and you'll need an Azure subscription and have to set up &lt;code&gt;Bing Search&lt;/code&gt; and &lt;code&gt;Bing Speech&lt;/code&gt;. Guide for setting up Azure cognitive services can be found &lt;a href="https://docs.microsoft.com/en-us/azure/cognitive-services/cognitive-services-apis-create-account"&gt;here&lt;/a&gt;. Happy hacking! I hope your kids will have as much fun with it as mine have had.&lt;/p&gt;
</content>
		<summary>&lt;p&gt;&lt;a href="https://github.com/mholo65/alpha-beta"&gt;Alpha-Beta&lt;/a&gt; is a simple learning game I made for my children about a year ago that I'm now open sourcing. It's a fun way for kids to learn to write words, and locate keys on the keyboard. The game picks a random word from a list for the user to type. It uses Azure cognitive services like &lt;a href="https://docs.microsoft.com/en-us/azure/cognitive-services/bing-image-search/"&gt;Bing Image Search&lt;/a&gt; for searching related images and &lt;a href="https://docs.microsoft.com/en-us/azure/cognitive-services/speech/home"&gt;Bing Speech&lt;/a&gt; for reading the word out loud. See it in action below:&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://martinbjorkstrom.com/posts/2018-09-19-revisiting-nuget-client-libraries" />
		<id>http://martinbjorkstrom.com/posts/2018-09-19-revisiting-nuget-client-libraries</id>
		<title>Revisiting the NuGet v3 Libraries</title>
		<updated>2018-09-19T00:00:00Z</updated>
		<content>&lt;h1 id="background"&gt;Background&lt;/h1&gt;
&lt;p&gt;This is a follow-up post to Dave Glick's three part blog post &lt;a href="https://daveaglick.com/posts/exploring-the-nuget-v3-libraries-part-1"&gt;&amp;quot;Exploring the NuGet v3 Libraries&amp;quot;&lt;/a&gt;. To this day, this is the only documentation provided for the NuGet Client SDK and is even being referenced from &lt;a href="https://docs.microsoft.com/en-us/nuget/reference/nuget-client-sdk"&gt;Microsoft's official documentation&lt;/a&gt;. I found Dave's blog posts very valuable when implementing the &lt;a href="https://github.com/cake-build/cake/pull/1768/files"&gt;in-process NuGet Client for Cake&lt;/a&gt;, and I have used Dave as a sounding board for everything NuGet related ever since. Thank you Dave, for being such a great guy!&lt;/p&gt;
&lt;p&gt;Anyhow, Dave's posts focuses on using the &lt;a href="https://www.nuget.org/packages/NuGet.PackageManagement/"&gt;NuGet.PackageManagement&lt;/a&gt; bits for installing packages. This has it's caveats, for example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.nuget.org/packages/NuGet.PackageManagement/"&gt;NuGet.PackageManagement&lt;/a&gt; is one of the few NuGet client libraries that doesn't target &lt;code&gt;netstandard&lt;/code&gt;. This is a no-go if you'd like to install NuGet packages from a .NET Core application. Fortunately, &lt;a href="https://twitter.com/aelij"&gt;Eli Arbel&lt;/a&gt; has created an &lt;a href="https://www.nuget.org/packages/NuGet.PackageManagement.NetStandard/"&gt;unofficial netstandard port&lt;/a&gt;, which I nowadays also help maintain. Maintaining a fork is painful however, and requires some extra work to keep up with the official NuGet releases.&lt;/li&gt;
&lt;li&gt;It's tightly coupled with the .NET project system, which I really don't care about in my use case (more on my use case below).&lt;/li&gt;
&lt;li&gt;It makes you implement &lt;a href="https://github.com/cake-build/cake/tree/17488d0c5bd2ca8a4a6815cd2f0bb307ee17e9ac/src/Cake.NuGet/Install"&gt;ugly workarounds&lt;/a&gt; in order to tweak the libraries to work as you want ?&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="alternative-approaches"&gt;Alternative approaches&lt;/h1&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;There's more than one way to skin a cat. But even more ways to install NuGet packages.&lt;/p&gt;
&lt;p&gt;-- &lt;cite&gt;Anonymous&lt;/cite&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;One alternative approach I've looked at is using the &lt;a href="https://www.nuget.org/packages/NuGet.Commands"&gt;NuGet.Commands&lt;/a&gt;, which contains &lt;em&gt;&amp;quot;Complete commands common to command-line and GUI NuGet clients&amp;quot;&lt;/em&gt; but doesn't depend on NuGet.PackageManagement, (weird, huh?). The reason why I didn't investigate this further is that it also seems to be tightly coupled with the .NET project system. Another alternative would simply be to use the service-based &lt;a href="https://docs.microsoft.com/en-us/nuget/api/overview"&gt;NuGet API&lt;/a&gt; directly. I've explored this alternative, but it would require quite a lot of effort to get something like package installation working.&lt;/p&gt;
&lt;h1 id="going-deeper"&gt;Going deeper&lt;/h1&gt;
&lt;p&gt;After reading through the &lt;code&gt;NuGet.Client&lt;/code&gt; source on &lt;a href="https://github.com/NuGet/NuGet.Client"&gt;Github&lt;/a&gt; and the NuGet API specification I've learned a simpler, more straightforward way to install NuGet packages. This approach doesn't rely on &lt;code&gt;NuGet.PackageManagement&lt;/code&gt;, &lt;code&gt;NuGet.Commands&lt;/code&gt;, or &lt;code&gt;NuGet.ProjectModel&lt;/code&gt; and is therefore completely decoupled from the .NET project system. I'm currently investigating this approach in &lt;a href="https://github.com/mholo65/depends"&gt;Depends&lt;/a&gt; while working on a new feature, and will most probably also implement it in Cake. This new approach &amp;quot;only&amp;quot; depends on the following NuGet libraries:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.nuget.org/packages/NuGet.Common/"&gt;&lt;code&gt;NuGet.Common&lt;/code&gt;&lt;/a&gt; - Includes some required common types such as NuGet's own logger abstraction.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.nuget.org/packages/NuGet.Configuration/"&gt;&lt;code&gt;NuGet.Configuration&lt;/code&gt;&lt;/a&gt; - NuGet's client configuration settings implementation.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.nuget.org/packages/NuGet.Frameworks/"&gt;&lt;code&gt;NuGet.Frameworks&lt;/code&gt;&lt;/a&gt; - The understanding of different target framework monikers.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.nuget.org/packages/NuGet.Packaging/"&gt;&lt;code&gt;NuGet.Packaging&lt;/code&gt;&lt;/a&gt; - NuGet's implementation for reading nupkg package and nuspec package specification files.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.nuget.org/packages/NuGet.Packaging/"&gt;&lt;code&gt;NuGet.Packaging.Core&lt;/code&gt;&lt;/a&gt; - The core data structures for &lt;code&gt;NuGet.Packaging&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.nuget.org/packages/NuGet.Protocol"&gt;&lt;code&gt;NuGet.Protocol&lt;/code&gt;&lt;/a&gt; - The NuGet protocol implementation. Supports both V2 and V3 feeds.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.nuget.org/packages/NuGet.Resolver"&gt;&lt;code&gt;NuGet.Resolver&lt;/code&gt;&lt;/a&gt; - NuGet's dependency resolver.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.nuget.org/packages/NuGet.Versioning"&gt;&lt;code&gt;NuGet.Versioning&lt;/code&gt;&lt;/a&gt; - NuGet's implementation of Semantic Versioning.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;What we are going to do next is:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Resolve all package dependency information recursively using &lt;code&gt;NuGet.Protocol&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Resolve the dependency graph from the list of available packages using &lt;code&gt;NuGet.Resolver&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Download all the packages in the dependency graph using &lt;code&gt;NuGet.Protocol&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Extract the content from the NuGet package using &lt;code&gt;NuGet.Packaging&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Locate the best matching assemblies with regards to the current target framework in the extracted package using &lt;code&gt;NuGet.Frameworks&lt;/code&gt; and &lt;code&gt;NuGet.Packaging&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="resolving-package-and-its-dependencies"&gt;Resolving package and its dependencies&lt;/h2&gt;
&lt;p&gt;We must learn to walk before we can run. Therefore, we will first look at the basics on how to retrieve dependency information for a single package (see code below).&lt;/p&gt;
&lt;p&gt;We begin by creating a &lt;code&gt;ISettings&lt;/code&gt; and loading the default settings (i.e. &lt;code&gt;nuget.config&lt;/code&gt;). This will use the default conventions as described &lt;a href="https://docs.microsoft.com/en-us/nuget/consume-packages/configuring-nuget-behavior#config-file-locations-and-uses"&gt;here&lt;/a&gt; for locating NuGet configuration. We'll need this to get the available NuGet sources for retrieving package dependency information. Next we'll create a &lt;code&gt;SourceRepositoryProvider&lt;/code&gt; and pass the &lt;code&gt;ISettings&lt;/code&gt; and the default NuGet V3 &lt;code&gt;INuGetResourceProvider&lt;/code&gt;'s. We can think of this as a plugin system for NuGet repositories (we will look more into what they do soon). The documentation states the following:&lt;/p&gt;
&lt;blockquote class="blockquote"&gt;
&lt;p&gt;INuGetResourceProviders are imported by SourceRepository. They exist as singletons which span all sources, and are responsible for determining if they should be used for the given source when TryCreate is called. The provider determines the caching. Resources may be cached per source, but they are normally created new each time to allow for caching within the context they were created in. Providers may retrieve other resources from the source repository and pass them to the resources they create in order to build on them.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Next, we'll create the default null logger, but for any real usage I strongly suggest implementing your own &lt;code&gt;ILogger&lt;/code&gt;. Then, we'll iterate through all repositories provided by the &lt;code&gt;SourceRepositoryProvider&lt;/code&gt;. For each &lt;code&gt;SourceRepository&lt;/code&gt; we'll resolve a &lt;code&gt;DependencyInfoResource&lt;/code&gt;. This is where the NuGet Resource Providers comes to play. The default V3 provider registered previously will resolve this for us and make sure other resource's needed also are created. This specific resource, as the name indicates, is used for retrieving dependency information for packages. Lastly we call the &lt;code&gt;ResolvePackage&lt;/code&gt; method on the &lt;code&gt;DependencyInfoResource&lt;/code&gt; to get the dependency information. We pass in a &lt;code&gt;NuGetFramework&lt;/code&gt; which represents our target framework. This will automatically filter out any dependencies that are not applicable for our target framework and only focus on the best matching dependencies.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-csharp"&gt;var packageId = &amp;quot;cake.nuget&amp;quot;;
var version = &amp;quot;0.30.0&amp;quot;;
var framework = &amp;quot;net46&amp;quot;;

var package = new PackageIdentity(packageId, NuGetVersion.Parse(version));
var settings = Settings.LoadDefaultSettings(root: null);
var sourceRepositoryProvider = new SourceRepositoryProvider(settings, Repository.Provider.GetCoreV3());
var nuGetFramework = NuGetFramework.ParseFolder(framework);
var logger = NullLogger.Instance;

using (var cacheContext = new SourceCacheContext())
{
    foreach (var sourceRepository in sourceRepositoryProvider.GetRepositories())
    {
        var dependencyInfoResource = await sourceRepository.GetResourceAsync&amp;lt;DependencyInfoResource&amp;gt;();
        var dependencyInfo = await dependencyInfoResource.ResolvePackage(
            package, nuGetFramework, cacheContext, logger, CancellationToken.None);

        if (dependencyInfo != null)
        {
            Console.WriteLine(dependencyInfo);
            return;
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Running the above code should output the following.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Cake.NuGet.0.30.0 : Cake.Core [0.30.0, ), Newtonsoft.Json [11.0.2, ), NuGet.Frameworks [4.7.0, ), NuGet.PackageManagement [4.7.0, ), NuGet.ProjectModel [4.7.0, ), NuGet.Versioning [4.7.0, )
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then what? In order to get dependency information for all packages in the dependency graph, we need to recursively call &lt;code&gt;ResolvePackage&lt;/code&gt; for every dependency. One such implementation could look something like the code below. We use a &lt;code&gt;HashSet&amp;lt;SourcePackageDependencyInfo&amp;gt;&lt;/code&gt; for storing all the packages. Note that we use the &lt;code&gt;PackageIdentityComparer&lt;/code&gt; as comparer. This will only compare the &lt;code&gt;PackageIdentity&lt;/code&gt; (id + version), and not compare any dependencies. We will assume that if the identity matches, the dependencies &lt;em&gt;should&lt;/em&gt; also match.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-csharp"&gt;var settings = Settings.LoadDefaultSettings(root: null);
var sourceRepositoryProvider = new SourceRepositoryProvider(settings, Repository.Provider.GetCoreV3());

using (var cacheContext = new SourceCacheContext())
{
    var repositories = sourceRepositoryProvider.GetRepositories();
    var availablePackages = new HashSet&amp;lt;SourcePackageDependencyInfo&amp;gt;(PackageIdentityComparer.Default);
    await GetPackageDependencies(
        new PackageIdentity(&amp;quot;cake.nuget&amp;quot;, NuGetVersion.Parse(&amp;quot;0.30.0&amp;quot;)),
        NuGetFramework.ParseFolder(&amp;quot;net46&amp;quot;), cacheContext, NullLogger.Instance, repositories, availablePackages);

    foreach (var availablePackage in availablePackages)
    {
        Console.WriteLine(availablePackage);
    }
}

async Task GetPackageDependencies(PackageIdentity package,
    NuGetFramework framework,
    SourceCacheContext cacheContext,
    ILogger logger,
    IEnumerable&amp;lt;SourceRepository&amp;gt; repositories,
    ISet&amp;lt;SourcePackageDependencyInfo&amp;gt; availablePackages)
{
    if (availablePackages.Contains(package)) return;

    foreach (var sourceRepository in repositories)
    {
        var dependencyInfoResource = await sourceRepository.GetResourceAsync&amp;lt;DependencyInfoResource&amp;gt;();
        var dependencyInfo = await dependencyInfoResource.ResolvePackage(
            package, framework, cacheContext, logger, CancellationToken.None);

        if (dependencyInfo == null) continue;

        availablePackages.Add(dependencyInfo);
        foreach (var dependency in dependencyInfo.Dependencies)
        {
            await GetPackageDependencies(
                new PackageIdentity(dependency.Id, dependency.VersionRange.MinVersion),
                framework, cacheContext, logger, repositories, availablePackages);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above code should then output the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Cake.NuGet.0.30.0 : Cake.Core [0.30.0, ), Newtonsoft.Json [11.0.2, ), NuGet.Frameworks [4.7.0, ), NuGet.PackageManagement [4.7.0, ), NuGet.ProjectModel [4.7.0, ), NuGet.Versioning [4.7.0, )
Cake.Core.0.30.0
Newtonsoft.Json.11.0.2
NuGet.Frameworks.4.7.0
NuGet.PackageManagement.4.7.0 : Microsoft.Web.Xdt [2.1.2, ), NuGet.Commands [4.7.0, ), NuGet.Resolver [4.7.0, )
Microsoft.Web.Xdt.2.1.2
NuGet.Resolver.4.7.0 : NuGet.Protocol [4.7.0, )
NuGet.Protocol.4.7.0 : NuGet.Configuration [4.7.0, ), NuGet.Packaging [4.7.0, )
NuGet.Packaging.4.7.0 : Newtonsoft.Json [9.0.1, ), NuGet.Packaging.Core [4.7.0, )
NuGet.Packaging.Core.4.7.0 : NuGet.Common [4.7.0, ), NuGet.Versioning [4.7.0, )
NuGet.Versioning.4.7.0
NuGet.Common.4.7.0 : NuGet.Frameworks [4.7.0, )
Newtonsoft.Json.9.0.1
NuGet.Configuration.4.7.0 : NuGet.Common [4.7.0, )
NuGet.Commands.4.7.0 : NuGet.Credentials [4.7.0, ), NuGet.ProjectModel [4.7.0, )
NuGet.ProjectModel.4.7.0 : NuGet.DependencyResolver.Core [4.7.0, )
NuGet.DependencyResolver.Core.4.7.0 : NuGet.LibraryModel [4.7.0, ), NuGet.Protocol [4.7.0, )
NuGet.LibraryModel.4.7.0 : NuGet.Common [4.7.0, ), NuGet.Versioning [4.7.0, )
NuGet.Credentials.4.7.0 : NuGet.Protocol [4.7.0, )
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="resolve-the-dependency-graph-from-the-list-of-available-packages"&gt;Resolve the dependency graph from the list of available packages&lt;/h2&gt;
&lt;p&gt;As you can see in the output from the last code snippet in the previous chapter, we are depending on two different versions of &lt;code&gt;Newtonsoft.Json&lt;/code&gt;. &lt;code&gt;Cake.NuGet&lt;/code&gt; depends on 11.0.2 or greater while &lt;code&gt;NuGet.Packaging&lt;/code&gt; depends on 9.0.1 or greater. Other packages might have even more scenarios like this. At first it would be tempting to just &amp;quot;pick&amp;quot; the highest version, but what if &lt;code&gt;Newtonsoft.Json.9.0.1&lt;/code&gt; depended on package &lt;code&gt;FooBar.0.1.0&lt;/code&gt; and &lt;code&gt;Newtonsoft.Json.11.0.2&lt;/code&gt; didn't? If we just remove duplicate packages by keeping the highest version, we'd end up with an unnecessary package (&lt;code&gt;FooBar.0.1.0&lt;/code&gt;). Or what if &lt;code&gt;NuGet.Packaging&lt;/code&gt; also depended on &lt;code&gt;FooBar.0.1.0&lt;/code&gt; and we just removed duplicate packages by removing the lower version and it's dependencies? Then we'd end up with a missing dependency. This is where &lt;code&gt;NuGet.Resolver&lt;/code&gt; comes in handy. By passing the list of available package through the &lt;code&gt;NuGetResolver&lt;/code&gt; we can easily filter out any duplicate dependencies.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-csharp"&gt;var packageId = &amp;quot;cake.nuget&amp;quot;;
var settings = Settings.LoadDefaultSettings(root: null);
var sourceRepositoryProvider = new SourceRepositoryProvider(settings, Repository.Provider.GetCoreV3());

using (var cacheContext = new SourceCacheContext())
{
    var repositories = sourceRepositoryProvider.GetRepositories();
    var availablePackages = new HashSet&amp;lt;SourcePackageDependencyInfo&amp;gt;(PackageIdentityComparer.Default);
    await GetPackageDependencies(
        new PackageIdentity(&amp;quot;cake.nuget&amp;quot;, NuGetVersion.Parse(&amp;quot;0.30.0&amp;quot;)),
        NuGetFramework.ParseFolder(&amp;quot;net46&amp;quot;), cacheContext, NullLogger.Instance, repositories, availablePackages);

    var resolverContext = new PackageResolverContext(
        DependencyBehavior.Lowest,
        new[] { packageId },
        Enumerable.Empty&amp;lt;string&amp;gt;(),
        Enumerable.Empty&amp;lt;PackageReference&amp;gt;(),
        Enumerable.Empty&amp;lt;PackageIdentity&amp;gt;(),
        availablePackages,
        sourceRepositoryProvider.GetRepositories().Select(s =&amp;gt; s.PackageSource),
        NullLogger.Instance);

    var resolver = new PackageResolver();
    var packagesToInstall = resolver.Resolve(resolverContext, CancellationToken.None)
        .Select(p =&amp;gt; availablePackages.Single(x =&amp;gt; PackageIdentityComparer.Default.Equals(x, p)));

    foreach (var packageToInstall in packagesToInstall)
    {
        Console.WriteLine(packageToInstall);
    }
}
...
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="download-all-the-packages-in-the-dependency-graph"&gt;Download all the packages in the dependency graph&lt;/h2&gt;
&lt;p&gt;To download the NuGet package from the repository, we'll resolve a &lt;code&gt;DownloadResource&lt;/code&gt; from the &lt;code&gt;SourceRepository&lt;/code&gt; associated with the package and call &lt;code&gt;GetDownloadResourceResultAsync&lt;/code&gt;. This will return a &lt;code&gt;DownloadResourceResult&lt;/code&gt; which contains everything needed for obtaining information about the NuGet package and also extracting the package contents to disk.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-csharp"&gt;...
foreach (var packageToInstall in packagesToInstall)
{
    var downloadResource = await packageToInstall.Source.GetResourceAsync&amp;lt;DownloadResource&amp;gt;(CancellationToken.None);
    var downloadResult = await downloadResource.GetDownloadResourceResultAsync(
        packageToInstall,
        new PackageDownloadContext(cacheContext),
        SettingsUtility.GetGlobalPackagesFolder(settings),
        NullLogger.Instance, CancellationToken.None);
}
...
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="extract-the-content-from-the-nuget-package"&gt;Extract the content from the NuGet package&lt;/h2&gt;
&lt;p&gt;In order to extract the downloaded package, we'll create a &lt;code&gt;PackageExtractionContext&lt;/code&gt; and a &lt;code&gt;PackagePathResolver&lt;/code&gt;. Be careful with the &lt;code&gt;PackagePathResolver&lt;/code&gt; and &lt;strong&gt;ALWAYS&lt;/strong&gt; give an absolute path as root path. If you don't, it will not work correctly. Under the hood, it relies on a class called &lt;code&gt;PackagePathHelper&lt;/code&gt;, which according to code comments is &lt;a href="https://github.com/NuGet/NuGet.Client/blob/3803820961f4d61c06d07b179dab1d0439ec0d91/src/NuGet.Core/NuGet.Packaging/PackageExtraction/PackagePathHelper.cs#L15"&gt;a hack&lt;/a&gt;. &lt;em&gt;No wonder I spent some time figuring out how it works....&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-csharp"&gt;...
var packagePathResolver = new PackagePathResolver(Path.GetFullPath(&amp;quot;packages&amp;quot;));
var packageExtractionContext = new PackageExtractionContext(
    PackageSaveMode.Defaultv3,
    XmlDocFileSaveMode.None,
    NullLogger.Instance,
    new PackageSignatureVerifier(
        SignatureVerificationProviderFactory.GetSignatureVerificationProviders()),
    SignedPackageVerifierSettings.GetDefault());

foreach (var packageToInstall in packagesToInstall)
{
    ...
    await PackageExtractor.ExtractPackageAsync(
            downloadResult.PackageSource,
            downloadResult.PackageStream,
            packagePathResolver,
            packageExtractionContext,
            CancellationToken.None);
}
...
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="locate-best-matching-assemblies-with-regards-to-the-current-target-framework-in-the-package"&gt;Locate best matching assemblies with regards to the current target framework in the package&lt;/h2&gt;
&lt;p&gt;To read information from a NuGet package, we'll use a &lt;code&gt;PackageReaderBase&lt;/code&gt;. We use this to find e.g. lib items and framework items. In order to find the best matching items based on our target framework, we'll use a &lt;code&gt;FrameworkReducer&lt;/code&gt; to reduce the list of available target frameworks in the package down to the nearest match.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-csharp"&gt;var nuGetFramework = NuGetFramework.ParseFolder(&amp;quot;net46&amp;quot;);
...
var frameworkReducer = new FrameworkReducer();

foreach (var packageToInstall in packagesToInstall)
{
    ...
    var libItems = downloadResult.PackageReader.GetLibItems();
    var nearest = frameworkReducer.GetNearest(nuGetFramework, libItems.Select(x =&amp;gt; x.TargetFramework));
    Console.WriteLine(string.Join(&amp;quot;\n&amp;quot;, libItems
        .Where(x =&amp;gt; x.TargetFramework.Equals(nearest))
        .SelectMany(x =&amp;gt; x.Items)));

    var frameworkItems = downloadResult.PackageReader.GetFrameworkItems();
    nearest = frameworkReducer.GetNearest(nuGetFramework, frameworkItems.Select(x =&amp;gt; x.TargetFramework));
    Console.WriteLine(string.Join(&amp;quot;\n&amp;quot;, frameworkItems
        .Where(x =&amp;gt; x.TargetFramework.Equals(nearest))
        .SelectMany(x =&amp;gt; x.Items)));
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="if-package-is-already-downloaded-just-use-a-packagefolderreader"&gt;If package is already downloaded, just use a PackageFolderReader&lt;/h2&gt;
&lt;p&gt;If the NuGet package is already installed, there's no need to download the NuGet package in order to get the &lt;code&gt;DownloadResourceResult&lt;/code&gt; and from there obtain the &lt;code&gt;PackageReader&lt;/code&gt;. We can simply check if the package is already installed, using the &lt;code&gt;PackagePathResolver&lt;/code&gt; and then create a &lt;code&gt;PackageFolderReader&lt;/code&gt; from the installed path. This is where the &lt;code&gt;PackagePathResolver&lt;/code&gt; failed me many times, before I realized that absolute paths was a must.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-csharp"&gt;foreach (var packageToInstall in packagesToInstall)
{
    PackageReaderBase packageReader;
    var installedPath = packagePathResolver.GetInstalledPath(packageToInstall);
    if (installedPath == null)
    {
        // Install packages
        ...
        packageReader = downloadResult.PackageReader;
    }
    else
    {
        packageReader = new PackageFolderReader(installedPath);
    }

    var libItems = packageReader.GetLibItems();
    var nearest = frameworkReducer.GetNearest(nuGetFramework, libItems.Select(x =&amp;gt; x.TargetFramework));
    Console.WriteLine(string.Join(&amp;quot;\n&amp;quot;, libItems
        .Where(x =&amp;gt; x.TargetFramework.Equals(nearest))
        .SelectMany(x =&amp;gt; x.Items)));

    var frameworkItems = packageReader.GetFrameworkItems();
    nearest = frameworkReducer.GetNearest(nuGetFramework, frameworkItems.Select(x =&amp;gt; x.TargetFramework));
    Console.WriteLine(string.Join(&amp;quot;\n&amp;quot;, frameworkItems
        .Where(x =&amp;gt; x.TargetFramework.Equals(nearest))
        .SelectMany(x =&amp;gt; x.Items)));
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id="sample"&gt;Sample&lt;/h1&gt;
&lt;p&gt;A complete working example can be found &lt;a href="https://gist.github.com/mholo65/ad5776c36559410f45d5dcd0181a5c64"&gt;here&lt;/a&gt;. Thank you for reading this relatively long blog post and hopefully you learned a little bit more about the NuGet Client libraries (at least I did). Next thing to do is to refine this approach and eventually integrate it into Cake. Keep an eye out for the PR.&lt;/p&gt;
</content>
		<summary>&lt;p&gt;This is a follow-up post to Dave Glick's three part blog post &lt;a href="https://daveaglick.com/posts/exploring-the-nuget-v3-libraries-part-1"&gt;"Exploring the NuGet v3 Libraries"&lt;/a&gt;. To this day, this is the only documentation provided for the NuGet Client SDK and is even being referenced from &lt;a href="https://docs.microsoft.com/en-us/nuget/reference/nuget-client-sdk"&gt;Microsoft's official documentation&lt;/a&gt;. I found Dave's blog posts very valuable when implementing the &lt;a href="https://github.com/cake-build/cake/pull/1768/files"&gt;in-process NuGet Client for Cake&lt;/a&gt;, and I have used Dave as a sounding board for everything NuGet related ever since. Thank you Dave, for being such a great guy!&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://martinbjorkstrom.com/posts/2018-08-06-announcing-dotnet-depends" />
		<id>http://martinbjorkstrom.com/posts/2018-08-06-announcing-dotnet-depends</id>
		<title>Announcing dotnet depends</title>
		<updated>2018-08-06T00:00:00Z</updated>
		<content>&lt;h2 id="tldr"&gt;TL;DR;&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://github.com/mholo65/depends/releases/tag/0.1.0"&gt;dotnet depends v0.1.0&lt;/a&gt; has now been released. This is a tool for exploring dependencies in .NET projects, with an GUI heavily inspired from &lt;a href="https://wiki.yoctoproject.org/wiki/BitBake/GUI"&gt;bitbake's depexp&lt;/a&gt;. Hopefully this tool will be a valuable addition to your toolbox when e.g. debugging transitive dependencies. Install it by running: &lt;code&gt;dotnet tool install --global dotnet-depends&lt;/code&gt;, and report any issues and/or feature requests on &lt;a href="https://github.com/mholo65/depends"&gt;Github&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="background"&gt;Background&lt;/h2&gt;
&lt;p&gt;Ever since &lt;a href="https://daveaglick.com/posts/running-a-design-time-build-with-msbuild-apis"&gt;Dave Glick announced Buildalyzer&lt;/a&gt;, I knew I wanted to build something with it. I had been thinking about a dependency explorer, since you know, debugging transitive dependencies in .NET really sucks. It always takes a dozen of clicks on &lt;a href="https://www.nuget.org/"&gt;nuget.org&lt;/a&gt; and a couple of minutes scrolling up-and-down in &lt;code&gt;project.assets.json&lt;/code&gt; to figure out which dependency brought in package A, which in turn was incompatible with package B.&lt;/p&gt;
&lt;p&gt;At first, when I started playing with &lt;a href="https://github.com/daveaglick/Buildalyzer"&gt;Buildalyzer&lt;/a&gt;, I was determined that the tool should output a dependency graph in the &lt;a href="https://en.wikipedia.org/wiki/DOT_(graph_description_language)"&gt;DOT language&lt;/a&gt;, which in turn could be converted to SVG or PNG using &lt;a href="https://www.graphviz.org/"&gt;graphviz&lt;/a&gt;. After a few attempts I came to the conclusion that the graphs easily became too messy and was hard to interpret. I was close to accept my defeat, when I remembered a great tool called &lt;code&gt;depexp&lt;/code&gt; which I had used with &lt;a href="https://www.yoctoproject.org/"&gt;Yocto&lt;/a&gt; back in the days, when I was creating/tweaking embedded Linux distros (narrator: he still does, occasionally...).&lt;/p&gt;
&lt;p&gt;Next problem then... Since I wanted this to be a &lt;a href="https://docs.microsoft.com/en-us/dotnet/core/tools/global-tools"&gt;.NET Core global tool&lt;/a&gt;, how do I introduce a GUI like &lt;code&gt;depexp&lt;/code&gt; in a .NET Core console application? I then remembered the console UI toolkit for .NET &lt;a href="https://twitter.com/migueldeicaza/status/964352496243273728"&gt;Miguel de Icaza announced&lt;/a&gt;. So, I took a dependency on &lt;a href="https://github.com/migueldeicaza/gui.cs"&gt;Terminal.Gui / Gui.cs&lt;/a&gt;, and tweeted this:&lt;/p&gt;
&lt;blockquote class="twitter-tweet" data-lang="en"&gt;&lt;p lang="en" dir="ltr"&gt;Been playing with Buildalyzer and this is what I came up with. A simple dependency explorer for &lt;a href="https://twitter.com/hashtag/dotnet?src=hash&amp;amp;ref_src=twsrc%5Etfw"&gt;#dotnet&lt;/a&gt;. GUI influenced by bitbake&amp;#39;s depexp and powered by gui.cs.&lt;br&gt;&lt;br&gt;Source can be found here: &lt;a href="https://t.co/eJqSgjQ2ky"&gt;https://t.co/eJqSgjQ2ky&lt;/a&gt; &lt;a href="https://t.co/7DbESQUs75"&gt;pic.twitter.com/7DbESQUs75&lt;/a&gt;&lt;/p&gt;&amp;mdash; Martin Björkström (&amp;#64;mholo65) &lt;a href="https://twitter.com/mholo65/status/1014128499987288069?ref_src=twsrc%5Etfw"&gt;July 3, 2018&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;
&lt;p&gt;Feedback was awesome, so I submitted a couple of &lt;a href="https://github.com/migueldeicaza/gui.cs/pulls?q=is%3Apr+is%3Aclosed+author%3Amholo65"&gt;PR's to Gui.cs&lt;/a&gt; and awaited Buildalyzer v1.0.0 before releasing v0.1.0 of &lt;code&gt;dotnet depends&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Curious to see how it works? Install it by running: &lt;code&gt;dotnet tool install --global dotnet-depends&lt;/code&gt;, and then run &lt;code&gt;dotnet depends /path/to/myproject.csproj&lt;/code&gt;. If your project targets multiple frameworks, you can specify the target by appending the &lt;code&gt;-f|--framework &amp;lt;FRAMEWORK&amp;gt;&lt;/code&gt; option. Please remember to report any issues and/or feature requests on &lt;a href="https://github.com/mholo65/depends"&gt;Github&lt;/a&gt;. Happy hacking!&lt;/p&gt;
</content>
		<summary>&lt;p&gt;&lt;a href="https://github.com/mholo65/depends/releases/tag/0.1.0"&gt;dotnet depends v0.1.0&lt;/a&gt; has now been released. This is a tool for exploring dependencies in .NET projects, with an GUI heavily inspired from &lt;a href="https://wiki.yoctoproject.org/wiki/BitBake/GUI"&gt;bitbake's depexp&lt;/a&gt;. Hopefully this tool will be a valuable addition to your toolbox when e.g. debugging transitive dependencies. Install it by running: &lt;code&gt;dotnet tool install --global dotnet-depends&lt;/code&gt;, and report any issues and/or feature requests on &lt;a href="https://github.com/mholo65/depends"&gt;Github&lt;/a&gt;.&lt;/p&gt;</summary>
	</entry>
	<entry>
		<link href="http://martinbjorkstrom.com/posts/2018-07-05-hello-world" />
		<id>http://martinbjorkstrom.com/posts/2018-07-05-hello-world</id>
		<title>Hello World</title>
		<updated>2018-07-05T00:00:00Z</updated>
		<content>&lt;p&gt;So it has finally come to this. After procrastinating for a while now I've finally decided to setup a blog. The blog is a static site generated by &lt;a href="https://wyam.io/"&gt;Wyam&lt;/a&gt; and hosted on &lt;a href="https://www.netlify.com/"&gt;Netlify&lt;/a&gt;. You can find the source code for this blog &lt;a href="https://github.com/mholo65/mholo65"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I have lots and lots of interesting stuff I would like to blog about, some will happen and some will not. Because like most people, I'm also short on hours per day to spend on spare time tinkering. A couple of things that's in the pipeline though is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/mholo65/depends"&gt;Depends&lt;/a&gt;, a command line dependency explorer for .NET powered by &lt;a href="https://github.com/daveaglick/Buildalyzer"&gt;Buildalyzer&lt;/a&gt; and &lt;a href="https://github.com/migueldeicaza/gui.cs"&gt;gui.cs&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://cakebuild.net/"&gt;Cake (C# Make)&lt;/a&gt;, as some of you know, a lot of my spare time coding goes into Cake. My contributions are mostly concentrated in the Roslyn, NuGet, and tooling area. Maybe a deep dive in how Cake uses the &lt;a href="https://github.com/NuGet/NuGet.Client/"&gt;NuGet.Client&lt;/a&gt; libraries for installing addins and tools?&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.omnisharp.net/"&gt;OmniSharp&lt;/a&gt;, as some of you know, one of the reasons why I was invited as Cake maintainer was that I was working on intellisense support for &lt;code&gt;.cake&lt;/code&gt; files in OmniSharp. I've been thinking about a three part blog series where I explain what is what, and how it all ties together in order to support intellisense for Cake.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.microsoft.com/en-us/azure/service-fabric/"&gt;Service Fabric&lt;/a&gt;, microservices development and application lifecycle management done right. This is a really cool, open source, distributed systems platform from Microsoft that makes it easy to package, deploy, and manage scalable and reliable microservices and containers.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So, now that you know what's coming, subscribe to the feed below or follow me on &lt;a href="https://twitter.com/mholo65"&gt;Twitter&lt;/a&gt; to stay updated.&lt;/p&gt;
</content>
		<summary>&lt;p&gt;So it has finally come to this. After procrastinating for a while now I've finally decided to setup a blog. The blog is a static site generated by &lt;a href="https://wyam.io/"&gt;Wyam&lt;/a&gt; and hosted on &lt;a href="https://www.netlify.com/"&gt;Netlify&lt;/a&gt;. You can find the source code for this blog &lt;a href="https://github.com/mholo65/mholo65"&gt;here&lt;/a&gt;.&lt;/p&gt;</summary>
	</entry>
</feed>